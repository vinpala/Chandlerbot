{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bb3637251d4a74d9ec372b1da06db1ee7d284fb6"
   },
   "outputs": [],
   "source": [
    "!mkdir -p save/model/formatted_lines_sitcom/1-1_512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7e94c38d4690e845ea6891289db274817c05301d"
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "bucket_name = 'chandlerbotmodels'\n",
    "\n",
    "s3_file_path= 'model/4000_backup_bidir_model.tar'\n",
    "save_as = 'save/model/formatted_lines_sitcom/1-1_512/4000_backup_bidir_model.tar'\n",
    "\n",
    "\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id='',\n",
    "aws_secret_access_key=''\n",
    "    #aws_session_token=SESSION_TOKEN,\n",
    ")\n",
    "\n",
    "s3.download_file(bucket_name , s3_file_path, save_as)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f63ad9d9c10ccc2975ac9623eae72f1164b424e5"
   },
   "outputs": [],
   "source": [
    "!wget -c 'https://s3.amazonaws.com/chandlerbotmodels/model/4000_backup_bidir_model.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "745c16ce364dc33637d2c3bb5124325bcd30d19e"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3fef0e87e67012ed6f841e7f4b344a289222ce51"
   },
   "outputs": [],
   "source": [
    "#!rm save/model/formatted_lines_sitcom/1-1_512/2000_round2_bidir_model.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cfad49fb8b7503fb4b0216824abdd44efe206038"
   },
   "outputs": [],
   "source": [
    "!mv 2000_round2_bidir_model.tar save/model/formatted_lines_sitcom/1-1_512/2000_round2_bidir_model.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "702d4ed01e9c9ed3de757339101204c9dcb33b19"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a4270aaca615b388f9ec8db92b0178fb9295f2e7"
   },
   "outputs": [],
   "source": [
    "!mkdir -p save/training_data/formatted_lines_sitcom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "23972045cea14bd6a6aca17a27112b18cd61289f"
   },
   "outputs": [],
   "source": [
    "\n",
    "s3_file_path= 'training_data/4000_training_batches_64.tar'\n",
    "save_as = 'save/training_data/formatted_lines_sitcom/4000_training_batches_64.tar'\n",
    "s3.download_file(bucket_name , s3_file_path, save_as)\n",
    "s3_file_path= 'training_data/pairs.tar'\n",
    "save_as = 'save/training_data/formatted_lines_sitcom/pairs.tar'\n",
    "s3.download_file(bucket_name , s3_file_path, save_as)\n",
    "s3_file_path= 'training_data/voc.tar'\n",
    "save_as = 'save/training_data/formatted_lines_sitcom/voc.tar'\n",
    "s3.download_file(bucket_name , s3_file_path, save_as)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "38111591c752b893ec8665f06a076c02d53a3092"
   },
   "outputs": [],
   "source": [
    "!ls save/training_data/formatted_lines_sitcom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/9827g9ytuqqibb3/4000_backup_bidir_model.tar?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ea4266532b6fb3bf2eac93039d257c0f7ba84efc"
   },
   "outputs": [],
   "source": [
    "!mv 4000_backup_bidir_model.tar?dl=0 'save/model/formatted_lines_sitcom/1-1_512/4000_backup_bidir_model.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a48944095ec005ebc04587880da2e2041f210df2"
   },
   "outputs": [],
   "source": [
    "!ls 'save/model/formatted_lines_sitcom/1-1_512'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "025327a8e3630ed069167315d87cc6982f4fa730"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "74ea0f643ba9bdf8ea5664c05d3b850816a51ec3"
   },
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7fe504248b1b0cc406473db23703bfbd6778d2cd"
   },
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "58a80e9657746baeed6f6dd8f9af0f1c638ae0dd"
   },
   "outputs": [],
   "source": [
    "! ls \"../input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f153cd873c4025c888d624ea939b76a43322e2fe"
   },
   "outputs": [],
   "source": [
    "!mv \"../input/formatted_lines_sitcom.txt\" data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8c46b546504fe80083d76790e8c888b1869327ee"
   },
   "outputs": [],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "993abd9b19625c3e37096c88b9c6730766bb7484"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/ywk991112/pytorch-chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0a85300f3dd2df5cde687c586ea8971c0b7f19c1"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "15cd4cde1d9c8baf3ff0804c83fd25462b68222a"
   },
   "outputs": [],
   "source": [
    "!mv \"4000_backup_bidir_model.tar?dl=0\"  \"4000_backup_bidir_model.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "734cc219f27816b4791fdc0a31ee5ca659a3bf13"
   },
   "outputs": [],
   "source": [
    "!mkdir -p save/model/formatted_lines_sitcom/1-1_512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4b5a1c3074d5df2b67386d1809c091069c786ce1"
   },
   "outputs": [],
   "source": [
    "!mv 4000_backup_bidir_model.tar save/model/formatted_lines_sitcom/1-1_512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6b795515d6df08c5beefc5a0f87cd193eb60b5f7"
   },
   "outputs": [],
   "source": [
    "!cd pytorch-chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ac33bcf3f065da710f932e51a2e9f1430bb59c30"
   },
   "outputs": [],
   "source": [
    "!ls save/training_data/formatted_lines_sitcom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e87e4a46643d0a4a8ee0d34ef255326b80ee3afb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/1iwo8pk8f1dgbnm/pairs.tar?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "307d40a54af5a61cea12bbff13e2c28fc2f6a874",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/isa1uvw2n1yhl2x/voc.tar?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f59469709001eb4cf50cf62fcc2932f789d8e92a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9f7021d80544f148512bf14e012b6ac4598cdde0"
   },
   "outputs": [],
   "source": [
    "!mkdir save/training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "237d50d14c1455777dec48e0a92da5095172b963"
   },
   "outputs": [],
   "source": [
    "!mkdir -p save/training_data/formatted_lines_sitcom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "876e5ab2c5bd18a36e3ae606ad7ef79fc38d72ae"
   },
   "outputs": [],
   "source": [
    "!mv voc.tar?dl=0 voc.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7b2c79c0d2f0c55b7f34cad270a35a077c9bfbc9"
   },
   "outputs": [],
   "source": [
    "!mv voc.tar save/training_data/formatted_lines_sitcom "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "50ef3faad2b1992e558b8362af1d5d478fb664e0"
   },
   "outputs": [],
   "source": [
    "! ls pytorch-chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "170d4f015adef67b55b41cfffd813fa9b5dbf80a"
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/fqgxv47ws3syt51/load_round2.py?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0abcabf54b367bf9e392ebd9209c6141c7bf8c41"
   },
   "outputs": [],
   "source": [
    "!mv load_round2.py?dl=0 load.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6d5f7a92f751ebd358ed6158a4f3108889a55a73"
   },
   "outputs": [],
   "source": [
    "!rm pytorch-chatbot/load.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b5702d699e29703ef2adaaab86f9d62b047f5aa5"
   },
   "outputs": [],
   "source": [
    "!ls pytorch-chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e4235f70bc7000179b29bf4d49fe05469e87fbff"
   },
   "outputs": [],
   "source": [
    "!mv load.py pytorch-chatbot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "088b4ced31afef9c3f1789ede3f94a8cd2aa6d22"
   },
   "outputs": [],
   "source": [
    "!ls pytorch-chatbot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "522bf9fb3b8789d2138eb364b6f88efe9618ea99"
   },
   "outputs": [],
   "source": [
    "#!python pytorch-chatbot/main.py -tr data/formatted_lines_sitcom.txt -l save/model/formatted_lines_sitcom/1-1_512/4000_backup_bidir_model.tar -lr 0.0001 -it 4000 -b 64 -p 500 -s 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "74bb25c44cdc60497e2cf609a40bd2efb371671b"
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"pytorch-chatbot/\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from load import loadPrepareData\n",
    "from load import SOS_token, EOS_token, PAD_token\n",
    "from model import EncoderRNN, LuongAttnDecoderRNN\n",
    "from config import MAX_LENGTH, teacher_forcing_ratio, save_dir\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "\n",
    "cudnn.benchmark = True\n",
    "#############################################\n",
    "# generate file name for saving parameters\n",
    "#############################################\n",
    "def filename(reverse, obj):\n",
    "\tfilename = ''\n",
    "\tif reverse:\n",
    "\t\tfilename += 'reverse_'\n",
    "\tfilename += obj\n",
    "\treturn filename\n",
    "\n",
    "\n",
    "#############################################\n",
    "# Prepare Training Data\n",
    "#############################################\n",
    "def indexesFromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "# batch_first: true -> false, i.e. shape: seq_len * batch\n",
    "def zeroPadding(l, fillvalue=PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n",
    "\n",
    "def binaryMatrix(l, value=PAD_token):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "# convert to index, add EOS\n",
    "# return input pack_padded_sequence\n",
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    lengths = [len(indexes) for indexes in indexes_batch]\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "\n",
    "# convert to index, add EOS, zero padding\n",
    "# return output variable, mask, max length of the sentences in batch\n",
    "def outputVar(l, voc):\n",
    "    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.ByteTensor(mask)\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len\n",
    "\n",
    "# pair_batch is a list of (input, output) with length batch_size\n",
    "# sort list of (input, output) pairs by input length, reverse input\n",
    "# return input, lengths for pack_padded_sequence, output_variable, mask\n",
    "def batch2TrainData(voc, pair_batch, reverse):\n",
    "    if reverse:\n",
    "        pair_batch = [pair[::-1] for pair in pair_batch]\n",
    "    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = outputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len\n",
    "\n",
    "#############################################\n",
    "# Training\n",
    "#############################################\n",
    "\n",
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding,\n",
    "          encoder_optimizer, decoder_optimizer, batch_size, max_length=MAX_LENGTH):\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_variable = input_variable.to(device)\n",
    "    target_variable = target_variable.to(device)\n",
    "    mask = mask.to(device)\n",
    "\n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "\n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths, None)\n",
    "\n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_input = decoder_input.to(device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    # Run through decoder one time step at a time\n",
    "    if use_teacher_forcing:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden, _ = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            decoder_input = target_variable[t].view(1, -1) # Next input is current target\n",
    "            loss += F.cross_entropy(decoder_output, target_variable[t], ignore_index=EOS_token)\n",
    "    else:\n",
    "        for t in range(max_target_len):\n",
    "            decoder_output, decoder_hidden, decoder_attn = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs\n",
    "            )\n",
    "            _, topi = decoder_output.topk(1) # [64, 1]\n",
    "\n",
    "            decoder_input = torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input = decoder_input.to(device)\n",
    "            loss += F.cross_entropy(decoder_output, target_variable[t], ignore_index=EOS_token)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    clip = 50.0\n",
    "    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / max_target_len \n",
    "\n",
    "\n",
    "def trainIters(corpus, reverse, n_iteration, learning_rate, batch_size, n_layers, hidden_size,\n",
    "                print_every, save_every, dropout, loadFilename=None, attn_model='dot', decoder_learning_ratio=5.0):\n",
    "\n",
    "    voc, pairs = loadPrepareData(corpus)\n",
    "\n",
    "    # training data\n",
    "    corpus_name = os.path.split(corpus)[-1].split('.')[0]\n",
    "    training_batches = None\n",
    "    try:\n",
    "        training_batches = torch.load(os.path.join(save_dir, 'training_data', corpus_name,\n",
    "                                                   '{}_{}_{}.tar'.format(n_iteration, \\\n",
    "                                                                         filename(reverse, 'training_batches'), \\\n",
    "                                                                         batch_size)))\n",
    "    except FileNotFoundError:\n",
    "        print('Training pairs not found, generating ...')\n",
    "        training_batches = [batch2TrainData(voc, [random.choice(pairs) for _ in range(batch_size)], reverse)\n",
    "                          for _ in range(n_iteration)]\n",
    "        torch.save(training_batches, os.path.join(save_dir, 'training_data', corpus_name,\n",
    "                                                  '{}_{}_{}.tar'.format(n_iteration, \\\n",
    "                                                                        filename(reverse, 'training_batches'), \\\n",
    "                                                                        batch_size)))\n",
    "    # model\n",
    "    checkpoint = None\n",
    "    print('Building encoder and decoder ...')\n",
    "    embedding = nn.Embedding(voc.n_words, hidden_size)\n",
    "    encoder = EncoderRNN(voc.n_words, hidden_size, embedding, n_layers, dropout)\n",
    "    attn_model = 'dot'\n",
    "    decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.n_words, n_layers, dropout)\n",
    "    if loadFilename:\n",
    "        checkpoint = torch.load(loadFilename)\n",
    "        encoder.load_state_dict(checkpoint['en'])\n",
    "        decoder.load_state_dict(checkpoint['de'])\n",
    "    # use cuda\n",
    "    encoder = encoder.to(device)\n",
    "    decoder = decoder.to(device)\n",
    "\n",
    "    # optimizer\n",
    "    print('Building optimizers ...')\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate * decoder_learning_ratio)\n",
    "    if loadFilename:\n",
    "        encoder_optimizer.load_state_dict(checkpoint['en_opt'])\n",
    "        decoder_optimizer.load_state_dict(checkpoint['de_opt'])\n",
    "\n",
    "    # initialize\n",
    "    print('Initializing ...')\n",
    "    start_iteration = 1\n",
    "    perplexity = []\n",
    "    print_loss = 0\n",
    "    if loadFilename:\n",
    "        #start_iteration = checkpoint['iteration'] + 1\n",
    "        start_iteration = 0\n",
    "        perplexity = checkpoint['plt']\n",
    "    try:\n",
    "\t    for iteration in tqdm(range(start_iteration, n_iteration + 1)):\n",
    "\t        training_batch = training_batches[iteration - 1]\n",
    "\t        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "\n",
    "\t        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder,\n",
    "\t                     decoder, embedding, encoder_optimizer, decoder_optimizer, batch_size)\n",
    "\t        print_loss += loss\n",
    "\t        perplexity.append(loss)\n",
    "\n",
    "\t        if iteration % print_every == 0:\n",
    "\t            print_loss_avg = math.exp(print_loss / print_every)\n",
    "\t            print('%d %d%% %.4f' % (iteration, iteration / n_iteration * 100, print_loss_avg))\n",
    "\t            print_loss = 0\n",
    "\n",
    "\t        if (iteration % save_every == 0):\n",
    "\t            directory = os.path.join(save_dir, 'model', corpus_name, '{}-{}_{}'.format(n_layers, n_layers, hidden_size))\n",
    "\t            if not os.path.exists(directory):\n",
    "\t                os.makedirs(directory)\n",
    "\t            torch.save({\n",
    "\t                'iteration': iteration,\n",
    "\t                'en': encoder.state_dict(),\n",
    "\t                'de': decoder.state_dict(),\n",
    "\t                'en_opt': encoder_optimizer.state_dict(),\n",
    "\t                'de_opt': decoder_optimizer.state_dict(),\n",
    "\t                'loss': loss,\n",
    "\t                'plt': perplexity\n",
    "\t            }, os.path.join(directory, '{}_{}.tar'.format(iteration, filename(reverse, 'round2_bidir_model'))))\n",
    "    except Exception as e:  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ae6be3e9143f35ec6e477c46f58764a05186cb60"
   },
   "outputs": [],
   "source": [
    "def parseFilename(filename, test=False):\n",
    "    filename = filename.split('/')\n",
    "    dataType = filename[-1][:-4] # remove '.tar'\n",
    "    parse = dataType.split('_')\n",
    "    reverse = 'reverse' in parse\n",
    "    layers, hidden = filename[-2].split('_')\n",
    "    n_layers = int(layers.split('-')[0])\n",
    "    hidden_size = int(hidden)\n",
    "    return n_layers, hidden_size, reverse\n",
    "n_layers, hidden_size, reverse = parseFilename('save/model/formatted_lines_sitcom/1-1_512/4000_backup_bidir_model.tar')\n",
    "print(n_layers, hidden_size, reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "38758f10eeaab30261464bf85b055bf92656fbde"
   },
   "outputs": [],
   "source": [
    "loadFilename='save/model/formatted_lines_sitcom/1-1_512/4000_backup_bidir_model.tar'\n",
    "n_iteration=1500\n",
    "learning_rate=0.0001\n",
    "batch_size=64\n",
    "print_every=500\n",
    "save_every=1500\n",
    "dropout=0.1\n",
    "trainIters('data/formatted_lines_sitcom.txt', reverse, n_iteration, learning_rate, batch_size,\n",
    "                    n_layers, hidden_size, print_every, save_every, dropout, loadFilename=loadFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1340427aaade41390aa4a2fdcd166b154eb68d52"
   },
   "outputs": [],
   "source": [
    "#!python pytorch-chatbot/main.py -tr data/formatted_lines_sitcom.txt -l save/model/formatted_lines_sitcom/1-1_512/4000_backup_bidir_model.tar -lr 0.0001 -it 4000 -b 64 -p 500 -s 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "afd1415a953b1523161cf3beda619765b745d24d"
   },
   "outputs": [],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4db94c9e5eb974ee48af874959a856d518723517"
   },
   "outputs": [],
   "source": [
    "!ls save/model/formatted_lines_sitcom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7851be8920a84b84fa09c7a96d72df41bfd60a24"
   },
   "outputs": [],
   "source": [
    "!ls save/model/formatted_lines_sitcom/1-1_512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4c44588aded86d4a9dc9a26f9a7567362ae93b73"
   },
   "outputs": [],
   "source": [
    "!pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "85929bd8a61649d193f0f8808be254c8c1cd402d"
   },
   "outputs": [],
   "source": [
    "!ls save/training_data/formatted_lines_sitcom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "55a7c369fbf5f2119797f0705f9a433e11e98f79"
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "bucket_name = 'chandlerbotmodels'\n",
    "\n",
    "content = open('save/training_data/formatted_lines_sitcom/voc.tar', 'rb')\n",
    "s3 = boto3.client('s3')\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id='',\n",
    "    aws_secret_access_key='',\n",
    "    #aws_session_token=SESSION_TOKEN,\n",
    ")\n",
    "s3.put_object(\n",
    "   Bucket=bucket_name, \n",
    "   Key='training_data/voc.tar', \n",
    "   Body=content\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4ff7c399742a14cfad5e6c5adf78e4344c471b24"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
